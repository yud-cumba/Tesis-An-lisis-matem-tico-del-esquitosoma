\section{Variables aleatorias}
En ocasiones, dado un experimento aleatorio, estamos interesados en alguna característica numérica del resultado que se obtiene. Por ejemplo, al considerar el lanzamiento de un par de dados, pudiéramos estar interesados no en el resultado específico que se obtiene con cada dado, sino en la suma de ellos.\\
Nuestra primera dificultad es que no todos los espacios muestrales $\Omega$ son subconjuntos de $\R$, por ello, es necesario introducir la definición de una función que traslade los elementos de $\Omega$ a números reales con los cuales podamos trabajar matemáticamente.\\
Las demostraciones de los resultados expuestos en este capítulo se pueden encontrar en \cite{intro-probabilidad}, \cite{Feller},\cite{Rincon1} \cite{Rincon2}.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
\begin{Def}
El $\sigma-$álgebra de Borel en $\R$ denotado por $\mathscr{B}(\R)$ es
$$\mathscr{B}(\R)=\sigma(\{(a,\thinspace b)\subset\R:a\leq b\})$$
\end{Def}
\begin{Prop}
\textbf{ }\\
\begin{enumerate}
    \item Todo intervalo de $\R$ es un booreliano.
    \item Los subconjuntos cerrados y abiertos de $\R$ son borelianos
\end{enumerate}
\end{Prop}
\begin{Def}
Una función $\phi:\R^n\rightarrow\R^m$ es llamada boreliana si $\phi^{-1}(B)$ es un conjunto boreliano de $R^{-1}$ para todo boreliano B de $\R$.
\end{Def}
Recuérdese que si $\phi:\R^n\rightarrow\R^m$ es cualquier función, se cumple que $\phi^{-1}(B^c)=[\phi^{-1}(B)]^c$
 $\phi^{-1}(\bigcup_{\lambda}B_{\lambda})=\bigcup_{\lambda}\phi^{-1}(B_\lambda)$. Esto
implica que $\{B\subset \R^m: \phi^{-1}(B)\in B(\R^n)\}$ es un $\sigma$-álgebra de subconjuntos de $R^m$ , de manera que, para demostrar que una
cierta función f es boreliana, basta con probar que $\phi^{-1}(B)$ es un conjunto boreliano de $\R^n$ para cualquier elemento B abierto (o cualquier elemento B de una familia de generadores de los borelianos de $\R^m$).
Con base de esta idea, se pueden demostrar las siguientes proposiciones.
\begin{Prop}
$\phi:\R^n\rightarrow\R^m$,  $g:\R^m\rightarrow\R^p$ son borelianos, entonces $g\circ\phi$ es boreliano
\end{Prop}
\begin{Prop} Si $\phi:\R^n\rightarrow\R^m$ es continua, entonces es boreliana.
\end{Prop}
\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{Def}
    Sean $(\Omega_1,\mathscr{F}_1)$, $(\Omega_2,\mathscr{F}_2)$ espacios medibles. Una variable aleatoria (llamado función medible en teoría de la medida) es una función $X:\Omega_1\rightarrow \Omega_2$ tal que para cualquier $F\in\mathscr{F}_2$ se cumple que $$X^{-1}(F)\in\mathscr{F}_1.$$
\end{Def}
 Al conjunto $X(\Omega_1)$ se le conocerá como el conjunto de estados de X\\\\
\begin{Obs}
    Si el conjunto de estados $X(\Omega_1)$ es numerable o finito, entonces $X$ será llamado una variable aleatoria discreta.
\end{Obs}
\begin{Ejm}
  Se tiene un experimento aleatorio que consiste en lanzar 2 dados, cuyo  espacio muestral es $$\Omega_1=\{(1,1),\ldots,(1,6),\thinspace(2,1),\ldots\ldots,(2,6),\ldots,(6,6)\}$$ con el $\sigma-$álgebra asociado $\mathscr{P}(\Omega)$.\\ 
   Si queremos obtener la diferencia entre el mayor y el menor de los números que se obtienen al lanzar los dos dados, se define a la variable aleatoria $X$ como $$X:\Omega_1\rightarrow \{0,\thinspace 1,\ldots\},$$ donde $X(a,b)=\max \{a,b\}-\min\{a,b\}$
\end{Ejm}
Si $(\Omega_1,\mathscr{F},P)$ es un espacio de probabilidad, gracias a a la variable aleatoria $X$ se puede definir una nueva medida de probabilidad $P_X$ sobre el espacio de medida $(\Omega_2,\mathscr{F}_2)$, definida como $P_X(F)=P(X^{-1}(F))$, ya que $X^{-1}(F)\in\mathscr{F}_1$. Además, $$P_X(\Omega_2)=P(X^{-1}(\Omega_2))=P(\Omega_1)=1$$ $$P_X\big(\bigcup_{k=1}^\infty F_k\big)=P(X^{-1}\big(\bigcup_{k=1}^\infty
F_k\big))=P \big(\bigcup_{k=1}^\infty X^{-1}(F_k) \big)=\sum_{k=1}^\infty P(X^{-1}(F_k))=\sum_{k=1}^\infty P_X(F_k)$$
de donde se concluye que $P_X(\Omega_2)= 1$ y $P_X$ es $\sigma-$aditiva.\\\\
De aquí se concluye que $P_X:\mathscr{F_2}\rightarrow [0,1]$ resulta ser también una medida de probabilidad, y es llamada medida de probabilidad inducida por la variable aleatoria $X$.\\\\
\begin{Obs}
    Para un uso más práctico , el conjunto\\ $X^{-1}(\{a\})=\{\omega\in\Omega: X(\omega)=a\}$será denotado $(X= a)$\\
\end{Obs}
Para hacer la escritura más corta, a menudo se omite el término de la variable aleatoria para $X$ suponiendo, en la mayoría de las veces que lo es, por ello escribiremos $P$ en lugar de $P_X$\\\\
Las variables aleatorias establecen una relación funcional entre elementos del espacio muestral asociado al experimento y números reales, por ello, de manera práctica, la mayoría de variables aleatorias discretas no puedan ser expresadas matemáticamente, por lo cual suelen usarse expresiones que den entender el comportamiento de la variable aleatoria. \\Algunos ejemplos de estos casos serían: $X$=\textit{"Número de fallecidos en Enero el 2020."}, $X$=\textit{"Cantidad de bacterias en determinado cultivo"}, $X$=\textit{"Número de infectados por día de determinada enfermedad."}, etc.\\

De un mismo experimento aleatorio se puede definir diferentes variables aleatorias.
\begin{Ejm}
    Al lanzar $3$ monedas al aire podemos asignar a cada suceso la variable aleatoria $X$=\textit{"Número de caras."}, pero también se puede definir otra variable aleatoria $Y$=\textit{"Número de sellos."}, cuyo espacio muestral es:
    $$\Omega = \{(C,C,C),(C,X,C), (X,C,C), (C,C,X), (X,X,C), (X,C,X), (X,X,C), (X,X,X)\}$$
Consideremos a $P$ como la probabilidad clásica sobre $\Omega$ y $P_X$, $P_Y$ la probabilidad inducida por las variables aleatorias $X$, $Y$, respectivamente.
Se desea saber cuál es la probabilidad de obtener $2$ caras al lanzar las $3$ monedas consecutivamente.
$$P_{X}(X=2)= P\big(X^{-1}(2)\big)= P\big(\big\{(C,X,C), (X,C,C), (C,C,X)\big\}\big)=\frac{3}{8}$$
Intuitivamente, esta probabilidad vendría a ser la misma a obtener solo un sello al lanzar las $3$ monedas.
En efecto,
$$P_{Y}(Y=1)= P\big(Y^{-1}(1)\big)= P\big(\big\{(C,X,C), (X,C,C), (C,C,X)\big\}\big)=\frac{3}{8}$$
Esto sucede como consecuencia a que el conjunto $(Y=1)$ tiene los mismos elementos que $(X=2)$.
\end{Ejm}
\begin{Prop}
    Si $X$ es una variable aleatoria y $c$ es una constante, entonces $c X$ también es una variable aleatoria.
    \label{prop-variableAl-cXesVA}
\end{Prop}
\begin{Prop}
    Si $X$ e $Y$ son variables aleatorias, entonces $X+Y$ es variable aleatoria
    \label{prop-variableAl-X+YesVA}
\end{Prop}
\begin{comment}
\begin{Def}
    Sea los espacios de probabilidad $(\Omega_1,\thinspace\mathscr{F}_1,\thinspace P_1)$, $(\Omega_2,\thinspace\mathscr{F}_2,\thinspace P_2)$.
    Un vector aleatorio es una función $X:\Omega_1\rightarrow\Omega_2$ tal que para cualquier conjunto B en $\mathscr{F}_2$, se cumple que la imagen inversa $X^{-1}(B)$ es un elemento de $\mathscr{F}_1$.
\end{Def}
Dado entonces que un vector aleatorio es una función de $\Omega$ en $\R^n$, éste
puede representar de la forma $X=(X_1,\ldots, X_n)$ en donde cada coordenada es una función de $\Omega$ en $\R$.
\begin{Prop}
    Una función $(X_1 , . . . , X_n):\Omega\rightarrow R^n$ es un vector aleatorio si, y sólo si, cada coordenada es una variable aleatoria.
\end{Prop}
El resultado es análogo al caso unidimensional y puede extenderse al caso de $n$ dimensiones.
En la mayoría de los casos, las definiciones y resultados son fácilmente extendidos a dimensiones mayores.\\
\begin{Obs}
    El vector aleatorio $(A,\thinspace B)$ se interpreta cuan probable es que suceda A y B a la vez. Es decir $P(A,\thinspace B)=P(A\cap B)$.
\end{Obs}
\end{comment}
\begin{Obs}
En ocasiones denotaremos a la probabilidad de que ocurran los sucesos $A$ y $B$ como $P(A,\thinspace B)$ en lugar de $P(A\cap B)$. Esto es para simplificar la notación cuando queremos expresar la probabilidad de múltiples conjuntos.
\end{Obs}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{comment}
\begin{Def}
Se dice que un conjunto $A\subset\R$ tiene medida cero si, para cualquier $\epsilon>0$, existe una colección finita o infinita numerable de intervalos abiertos $\{I_n\}$ tal que $A\subset\bigcup I_n$ y $\sum_{n} I_n<\epsilon$
\end{Def}
La familia de conjuntos borelianos, si bien es bastante grande, presenta una limitación consistente en que un conjunto de medida cero puede no ser boreliano. En un problema de probabilidad, esto a su vez se traduce en que puede haber subconjuntos de conjuntos de probabilidad
cero para los cuales, por no ser borelianos, no está definida la función de probabilidad P, y por ende, tampoco $P_X$. Esto limitaría inlcusive a la función X del cual queremos extraer un valor numérico, pues debido a esto, podría existir algún $B\in B(\R)$ tal que $X^{-1}(B)$ tenga medida cero pero no sea boreleano. Esto sigificaría que X dejaría de ser un variable aleatoria.
Por esa razón, es conveniente considerar una $\sigma-$álgebra más grande que los borelianos, que incluya a todos los conjuntos de medida cero.
\begin{Def}
Diremos que un conjunto $A \subset\R $es
Lebesgue medible si pertenece a la $\sigma$-álgebra de subconjuntos de $\R$ generada por los borelianos y los conjuntos de medida cero.
$\mathscr{L}=\sigma(\{B: B\in B(\R) \textit{ o } B \textit{ B tiene medida cero}\})$
\end{Def}
\begin{Prop}
Todo conjunto Lebesgue medible se puede expresar como la unión de un conjunto boreliano y un conjunto de medida cero.
\end{Prop}
\begin{Def}
La medida de Lebesgue m en el intervalo, es la única medida de probabilidad definida sobre los subconjuntos Lebesgue medibles tal que $m(I)$ es igual a la longitud de I para cualquier intervalo
$I\subset\R$
\end{Def}
La unicidad se demuestra usado la definición de $\pi-$sistema y puede ser encontrado en cualquier libro de teoría de medida o en \cite{curso_medida_rotger}. Además la existencia de esta medida fue demostrada por Henri Léon Lebesgue en el año 1902.\\
Gracias a esto podemos considerar $\mathscr{F}=\mathscr{L}$ el espacio de probabilidad $(\Omega,\mathscr{L},m)$, $\Omega\subset\R$ pero por cuestiones de notación seguiremos usando $P=m$ como medida de probabilidad.
\end{comment}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%