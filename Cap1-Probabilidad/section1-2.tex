\section{Algunas propiedades elementales}
La capacidad de estimar o predecir eventos es la esencia vital de la aplicación de los métodos del calculo de probabilidades.\\
Mientras mayor sea el número de datos que tengamos a disposición para calcular la probabilidad de que un evento suceda, mayor precisión obtendremos al calcular el resultado. Debido a la complejidad de las situaciones en los que es menester aplicarse el cálculo de la probabilidades, es imprescindible que existan ciertas propiedades que lo faciliten.\\
Las demostraciones de los resultados expuestos en este capítulo son de común conocimiento de aquellos que estudiamos matemática y se pueden encontrar en \cite{intro-probabilidad}, \cite{Feller},\cite{Rincon1}, \cite{Rincon2}.
\begin{Prop}
    Sea $(\Omega,\thinspace\mathscr{F},P)$ un espacio de probabilidad, $A,B$ conjuntos tal que, $A,B\subset\Omega$, se cumple que:
    \begin{enumerate}
        \item $P(A^c)=1-P(A)$.
        \item $P(\emptyset)=0$.
        \item Si $A\subseteq B$ entonces $P(A)\leq P(B)$.
        \item Si $A\subseteq B$ entonces $P(B-A)=P(B)-P(A)$.
    \end{enumerate}
\end{Prop}
\begin{Def}
    Sea $\Omega$ el espacio muestral de un experimento aleatorio. El conjunto de eventos $\{D_i\}^{n}_{i=1}$ es una partición finita de $\Omega$ si se cumplen las siguientes condiciones:
    \begin{enumerate}[a)]
        \item $D_i\cap D_j=\emptyset$ , para $i\not= j$.
        \item $\bigcup_{i=1}^n D_i=\Omega$.
        \item $D_i\subset\Omega$ $i=1,2,\ldots,n$.
        \item $D_i\not=\emptyset$, $i=1,2,\ldots,n$.
    \end{enumerate}
\end{Def}
Queremos destacar la importancia del siguiente resultado ya que establece un método práctico para calcular probabilidades. Gracias a esto, considerando un evento $A$, del cual queremos encontrar la probabilidad de que suceda, se trata de encontrar una partición de $A$ donde cada evento de esta partición sea más simple de calcular.
\begin{Prop}
    Sea un espacio de probabilidad $(\Omega,\mathscr{F},P)$, $\{A_k\}_{k=1}^n$ una partición finita de $\Omega$, se tiene que
    $$P(\bigcup_{k=1}^n A_k)=\sum_{k=1}^n P(A_k)$$ 
\end{Prop}
\begin{Cor}
    Si $(\Omega,\mathscr{F},P)$ es un espacio de probabilidad, $A$ y $B$ eventos, entonces se tiene que
    $$P(A\cup B)=P(A)+P(B)-P(A\cap B)$$
\end{Cor}
En algunos casos, nos topamos con una colección de eventos que tienen cada uno la misma probabilidad de que sucedan. A estos eventos se le conocen como equiprobables.
Dado $n,N\in\N$, tal que $n<N$, $\Omega=\{\omega_1,\ldots,\omega_N\}$ un espacio muestral y $A=\{\omega_1,\ldots,\omega_n\}$ un evento del espacio muestral $\Omega$.
Si suponemos que los conjuntos  $\{\omega_k\}_{k=1}^N$, son equiprobables, entonces $P(\{\omega_i\})=P(\{\omega_j\})$ para $i,j=1,2,\ldots,N$, y como consecuencia $$1=P(\bigcup_{k=1}^N \{\omega_k\})=\sum_{k=1}^N P(\{\omega_k\})=N P(\omega_k).$$
\begin{eqnarray}
    \label{probabilidadn}
    P(\omega_k)=\frac{1}{N}\quad k=1,2,\ldots ,N.
\end{eqnarray}
Además
$$P(A)=P(\bigcup_{k=1}^n \{\omega_k\})=\sum_{k=1}^n P(\{\omega_k\})=n P(\{\omega_k\})$$
Usando la expresión (\ref{probabilidadn})
$$P(A)=\frac{n}{N}.$$
Esta forma de calcular probabilidades, apoyado en la equiprobabilidad de los posibles resultados, es conocido en nuestro medio de actuación como la definición clásica de probabilidad.\\
 La historia confirma que esta forma de calcular probabilidades es una de las primeras en se usado; se aplicó con bastante éxito en problemas de juegos de azar y ayudó a sentar las bases para construir la teoría matemática.
\begin{Def}
    Sea $\Omega$ un espacio muestral $\Omega$ de cardinalidad finita y $A$ un subconjunto de este. Si $\#A$ denota la cardinalidad del conjunto $A$. Se define la probabilidad clásica del evento $A$ como el cociente $$P(A)=\frac{\#A}{\#\Omega}$$
    \label{defprobClásica}
\end{Def}
\begin{Ejm}
    Un clásico ejemplo de equiprobabilidad se presenta al observar un dado que es lanzado sobre una mesa y observar el número que muestra la cara superior.\\ Consideramos el espacio muestral al conjunto  $\Omega=\{1,\thinspace 2,\thinspace 3,\thinspace 4,\thinspace 5,\thinspace 6\}$. Si deseamos calcular la probabilidad (clásica) de obtener un número impar del evento $A$, es decir, la probabilidad de $A=\{1,\thinspace 3,\thinspace 5\}$, entonces $$P(A)=\frac{\#\{1,\thinspace 3,\thinspace 5\}}{\#\{1,\thinspace 2\thinspace 3,\thinspace 4,\thinspace 5,\thinspace 6\}}=\frac{3}{6}=0.5$$
\end{Ejm}
En ocasiones el resultado de un experimento aleatorio depende del resultado de otros que también aleatorios, los cuales se realizan consecutivamente.\\
\begin{Def}
    Sea $(\Omega,\mathscr{F},P)$ un espacio de probabilidad, $A,B\subset\Omega$ tal que $P(B)>0$. La probabilidad condicional de algún evento $A$, dado que el evento $B$ suceda previamente, es una función que se denota $P(\cdot\thinspace|\thinspace B):\Omega\rightarrow [0,1]$ y se define como $$P(A\thinspace|\thinspace B)=\frac{P(A\cap B)}{P(B)}$$
\end{Def}
Cuando ocurre un suceso antes de realizar otro experimento, se reduce el espacio muestral y es por eso que cambia la probabilidad. A veces es más fácil calcular la probabilidad condicionada teniendo en cuenta este cambio de espacio muestral.
No tiene por qué haber una relación temporal entre $A$ y $B$. Además $A$ puede anteceder en el tiempo a $B$, pasar después o quizá pueden ocurrir a la misma vez. $A$ puede causar $B$, viceversa o pueden no tener relación.\\
"Siendo la probabilidad condicional una probabilidad calculada en un espacio muestral reducido (el cual sería $B$), es de esperarse que esta tenga las mismas propiedades que cualquier medida de probabilidad."
\begin{Prop}
    $P(\cdot\thinspace|\thinspace B)$ es una medida de probabilidad con el espacio de medida $(\Omega,\mathscr{F})$
\end{Prop}
Gracias a esta propiedad tenemos una útil herramienta para calcular probabilidades conocida como la regla del producto, la cual se puede utilizar para determinar la probabilidad de la intersección de dos eventos. Esta ley se deriva de la definición de probabilidad condicional.
$$P(A\cap B)=P(A\thinspace|\thinspace B)P(B)$$
En los casos en si evento $A$ no altera la probabilidad de otro evento $B$, se puede hablar de un caso de independencia de probabilidad.
\begin{Def}
    Se dice que los eventos $A$ y $B$ son independientes si se cumple la igualdad $P(A\cap B)=P(A)P(B)$. Si agregamos la hipótesis de $B$ suceda irremediablemente, es decir, $P(B)>0$. La condición de independencia puede escribirse como $P(A\thinspace|\thinspace B)=P(A)$.
\end{Def}
Intuitivamente esto significa que la ocurrencia del evento $B$ no afecta en la ocurrencia al evento $A$.\\
El siguiente resultado es bastante útil cuando se quiere determinar la probabilidad de algún conjunto grande, bastará con hallar las probabilidades de conjuntos más pequeños y probabilidades condicionales con respecto a esos conjuntos
\begin{Teo}
    Sea $\{B_i\}^{n}_{i=1}$ una partición del espacio muestral $\Omega$ tal que $P(B_i)\not=0$, para  $i=1,\ldots,n$, para cualquier evento $A$, $$P(A)=\sum_{i=1}^n P(A\thinspace|\thinspace B_i)P(B_i)$$
\end{Teo}

